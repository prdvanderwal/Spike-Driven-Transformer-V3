[10:10:48.170445] Model = Spiking_vit_MetaFormer_Spike_SepConv(
  (downsample1_1): MS_DownSampling(
    (encode_conv): Conv2d(3, 16, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))
    (encode_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (ConvBlock1_1): ModuleList(
    (0): MS_ConvBlock_spike_SepConv(
      (Conv): SepConv_Spike(
        (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv1): Sequential(
          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (dwconv): Sequential(
          (0): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32, bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike3): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv2): Sequential(
          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      (conv1): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      (conv2): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (downsample1_2): MS_DownSampling(
    (encode_conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (encode_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (encode_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
  )
  (ConvBlock1_2): ModuleList(
    (0): MS_ConvBlock_spike_SepConv(
      (Conv): SepConv_Spike(
        (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv1): Sequential(
          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (dwconv): Sequential(
          (0): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64, bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike3): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv2): Sequential(
          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      (conv1): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (downsample2): MS_DownSampling(
    (encode_conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (encode_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (encode_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
  )
  (ConvBlock2_1): ModuleList(
    (0): MS_ConvBlock_spike_SepConv(
      (Conv): SepConv_Spike(
        (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv1): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (dwconv): Sequential(
          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike3): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv2): Sequential(
          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      (conv1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      (conv2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ConvBlock2_2): ModuleList(
    (0): MS_ConvBlock_spike_SepConv(
      (Conv): SepConv_Spike(
        (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv1): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (dwconv): Sequential(
          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike3): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv2): Sequential(
          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      (conv1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      (conv2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (downsample3): MS_DownSampling(
    (encode_conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (encode_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (encode_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
  )
  (block3): ModuleList(
    (0-5): 6 x MS_Block_Spike_SepConv(
      (conv): SepConv_Spike(
        (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv1): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (dwconv): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike3): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv2): Sequential(
          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (attn): MS_Attention_linear_with_LateralInhibition(
        (head_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (qe_conv): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (qe_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (qi_conv): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (qi_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (k_conv): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (k_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (v_conv): Sequential(
          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (v_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (attn_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (excitatory_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (inhibitory_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (combined_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (proj_conv): Sequential(
          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (drop_path): Identity()
      (mlp): MS_MLP(
        (fc1_conv): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
        (fc1_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (fc1_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (fc2_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        (fc2_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (fc2_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      )
    )
  )
  (downsample4): MS_DownSampling(
    (encode_conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (encode_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (encode_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
  )
  (block4): ModuleList(
    (0-1): 2 x MS_Block_Spike_SepConv(
      (conv): SepConv_Spike(
        (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv1): Sequential(
          (0): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (dwconv): Sequential(
          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike3): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv2): Sequential(
          (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (attn): MS_Attention_linear_with_LateralInhibition(
        (head_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (qe_conv): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (qe_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (qi_conv): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (qi_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (k_conv): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (k_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (v_conv): Sequential(
          (0): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (v_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (attn_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (excitatory_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (inhibitory_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (combined_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (proj_conv): Sequential(
          (0): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (drop_path): Identity()
      (mlp): MS_MLP(
        (fc1_conv): Conv1d(192, 768, kernel_size=(1,), stride=(1,))
        (fc1_bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (fc1_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (fc2_conv): Conv1d(768, 192, kernel_size=(1,), stride=(1,))
        (fc2_bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (fc2_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      )
    )
  )
  (head): Linear(in_features=192, out_features=1000, bias=True)
  (spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=1, Threshold=0.5000)
)
[10:10:48.170828] number of params (M): 5.28
[10:10:48.170959] base lr: 6.00e-04
[10:10:48.171055] actual lr: 1.20e-03
[10:10:48.171138] accumulate grad iterations: 1
[10:10:48.171222] effective batch size: 512
[10:10:48.194087] criterion = LabelSmoothingCrossEntropy()
[10:10:48.194311] Start training for 20 epochs
[10:10:57.070725] Epoch: [0]  [  0/505]  eta: 1:14:41  lr: 0.000000  loss: 6.9103 (6.9103)  acc1: 0.3906 (0.3906)  acc5: 2.3438 (2.3438)  time: 8.8738  data: 3.8986  max mem: 21157
[10:11:44.677435] Epoch: [0]  [100/505]  eta: 0:03:46  lr: 0.000048  loss: 6.9040 (6.9072)  acc1: 0.3906 (0.2901)  acc5: 1.1719 (1.5277)  time: 0.4759  data: 0.0002  max mem: 21157
[10:12:32.174186] Epoch: [0]  [200/505]  eta: 0:02:37  lr: 0.000095  loss: 6.8829 (6.9000)  acc1: 0.3906 (0.3245)  acc5: 2.3438 (1.7063)  time: 0.4761  data: 0.0002  max mem: 21157
[10:13:19.444539] Epoch: [0]  [300/505]  eta: 0:01:43  lr: 0.000143  loss: 6.8371 (6.8864)  acc1: 0.3906 (0.3867)  acc5: 2.7344 (1.9012)  time: 0.4715  data: 0.0002  max mem: 21157
[10:14:06.630407] Epoch: [0]  [400/505]  eta: 0:00:51  lr: 0.000190  loss: 6.7624 (6.8642)  acc1: 0.3906 (0.4276)  acc5: 3.5156 (2.1207)  time: 0.4719  data: 0.0002  max mem: 21157
[10:14:53.870774] Epoch: [0]  [500/505]  eta: 0:00:02  lr: 0.000238  loss: 6.6455 (6.8307)  acc1: 0.3906 (0.4569)  acc5: 2.3438 (2.2673)  time: 0.4694  data: 0.0003  max mem: 21157
[10:14:55.743521] Epoch: [0]  [504/505]  eta: 0:00:00  lr: 0.000240  loss: 6.6449 (6.8292)  acc1: 0.3906 (0.4587)  acc5: 2.3438 (2.2664)  time: 0.4684  data: 0.0002  max mem: 21157
[10:14:55.872872] Epoch: [0] Total time: 0:04:07 (0.4904 s / it)
[10:14:55.875953] Averaged stats: lr: 0.000240  loss: 6.6449 (6.8292)  acc1: 0.3906 (0.4544)  acc5: 2.3438 (2.2649)
[10:14:55.876938] * Train_Acc@1 0.454 Acc@5 2.265 loss 6.829
[10:14:55.878277] Saving model at epoch: 0
wandb: WARNING Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[10:14:59.510105] Test:  [ 0/20]  eta: 0:01:07  loss: 6.5750 (6.5750)  acc1: 0.7812 (0.7812)  acc5: 3.1250 (3.1250)  time: 3.3654  data: 3.1767  max mem: 21157
[10:15:02.504301] Test:  [19/20]  eta: 0:00:00  loss: 6.5808 (6.5737)  acc1: 0.3906 (0.7000)  acc5: 3.1250 (3.3600)  time: 0.3179  data: 0.1670  max mem: 21157
[10:15:02.572569] Test: Total time: 0:00:06 (0.3214 s / it)
[10:15:02.575876] * Acc@1 0.640 Acc@5 3.110 loss 6.579
[10:15:02.576662] Accuracy of the network on the 10000 test images: 0.6%
[10:15:02.577152] Max accuracy: 0.64%
[10:15:02.577568] Saving model at epoch: 0
[10:15:06.206727] Epoch: [1]  [  0/505]  eta: 0:28:21  lr: 0.000240  loss: 6.6257 (6.6257)  acc1: 0.3906 (0.3906)  acc5: 2.7344 (2.7344)  time: 3.3702  data: 2.7671  max mem: 21157
[10:15:53.511996] Epoch: [1]  [100/505]  eta: 0:03:23  lr: 0.000288  loss: 6.4768 (6.5501)  acc1: 0.3906 (0.5840)  acc5: 2.7344 (2.9162)  time: 0.4735  data: 0.0002  max mem: 21157
[10:16:40.766426] Epoch: [1]  [200/505]  eta: 0:02:28  lr: 0.000335  loss: 6.2563 (6.4536)  acc1: 0.3906 (0.6219)  acc5: 3.5156 (3.0725)  time: 0.4732  data: 0.0002  max mem: 21157
[10:17:28.189279] Epoch: [1]  [300/505]  eta: 0:01:38  lr: 0.000383  loss: 6.0484 (6.3468)  acc1: 0.3906 (0.6372)  acc5: 3.1250 (3.1626)  time: 0.4734  data: 0.0002  max mem: 21157
[10:18:15.465987] Epoch: [1]  [400/505]  eta: 0:00:50  lr: 0.000430  loss: 5.8649 (6.2431)  acc1: 0.7812 (0.6312)  acc5: 3.5156 (3.2877)  time: 0.4732  data: 0.0002  max mem: 21157
[10:19:02.781759] Epoch: [1]  [500/505]  eta: 0:00:02  lr: 0.000478  loss: 5.7371 (6.1516)  acc1: 0.7812 (0.6853)  acc5: 3.9062 (3.4072)  time: 0.4697  data: 0.0003  max mem: 21157
[10:19:04.656513] Epoch: [1]  [504/505]  eta: 0:00:00  lr: 0.000480  loss: 5.7291 (6.1483)  acc1: 1.1719 (0.6900)  acc5: 4.2969 (3.4236)  time: 0.4691  data: 0.0002  max mem: 21157
[10:19:04.798939] Epoch: [1] Total time: 0:04:01 (0.4791 s / it)
[10:19:04.800959] Averaged stats: lr: 0.000480  loss: 5.7291 (6.1492)  acc1: 1.1719 (0.7000)  acc5: 4.2969 (3.4363)
[10:19:04.801471] * Train_Acc@1 0.700 Acc@5 3.436 loss 6.149
[10:19:07.801091] Test:  [ 0/20]  eta: 0:00:59  loss: 5.4371 (5.4371)  acc1: 1.5625 (1.5625)  acc5: 4.2969 (4.2969)  time: 2.9963  data: 2.8239  max mem: 21157
[10:19:10.788502] Test:  [19/20]  eta: 0:00:00  loss: 5.4081 (5.4137)  acc1: 1.1719 (1.2800)  acc5: 5.0781 (5.5200)  time: 0.2991  data: 0.1714  max mem: 21157
[10:19:10.856312] Test: Total time: 0:00:06 (0.3026 s / it)
[10:19:10.860133] * Acc@1 1.280 Acc@5 5.650 loss 5.413
[10:19:10.860894] Accuracy of the network on the 10000 test images: 1.3%
[10:19:10.861160] Max accuracy: 1.28%
[10:19:10.861385] Saving model at epoch: 1
[10:19:13.834949] Epoch: [2]  [  0/505]  eta: 0:22:50  lr: 0.000480  loss: 5.7044 (5.7044)  acc1: 0.3906 (0.3906)  acc5: 4.6875 (4.6875)  time: 2.7130  data: 2.0478  max mem: 21157
[10:20:01.659605] Epoch: [2]  [100/505]  eta: 0:03:22  lr: 0.000528  loss: 5.6658 (5.6861)  acc1: 1.1719 (1.1139)  acc5: 5.4688 (5.0433)  time: 0.4723  data: 0.0002  max mem: 21157
[10:20:48.922645] Epoch: [2]  [200/505]  eta: 0:02:28  lr: 0.000575  loss: 5.6388 (5.6664)  acc1: 1.1719 (1.1233)  acc5: 5.8594 (5.1714)  time: 0.4727  data: 0.0002  max mem: 21157
[10:21:36.231377] Epoch: [2]  [300/505]  eta: 0:01:38  lr: 0.000623  loss: 5.5973 (5.6497)  acc1: 1.1719 (1.2069)  acc5: 5.8594 (5.3636)  time: 0.4725  data: 0.0002  max mem: 21157
[10:22:23.534734] Epoch: [2]  [400/505]  eta: 0:00:50  lr: 0.000670  loss: 5.5920 (5.6361)  acc1: 1.1719 (1.2537)  acc5: 6.6406 (5.5554)  time: 0.4723  data: 0.0002  max mem: 21157
[10:23:10.915626] Epoch: [2]  [500/505]  eta: 0:00:02  lr: 0.000718  loss: 5.5583 (5.6230)  acc1: 1.5625 (1.3294)  acc5: 7.4219 (5.7978)  time: 0.4705  data: 0.0002  max mem: 21157
[10:23:12.792471] Epoch: [2]  [504/505]  eta: 0:00:00  lr: 0.000720  loss: 5.5583 (5.6227)  acc1: 1.1719 (1.3266)  acc5: 7.4219 (5.8052)  time: 0.4694  data: 0.0002  max mem: 21157
[10:23:12.938139] Epoch: [2] Total time: 0:04:01 (0.4788 s / it)
[10:23:12.941872] Averaged stats: lr: 0.000720  loss: 5.5583 (5.6229)  acc1: 1.1719 (1.3506)  acc5: 7.4219 (5.8296)
[10:23:12.943489] * Train_Acc@1 1.351 Acc@5 5.830 loss 5.623
[10:23:15.802472] Test:  [ 0/20]  eta: 0:00:57  loss: 5.1241 (5.1241)  acc1: 0.7812 (0.7812)  acc5: 7.4219 (7.4219)  time: 2.8536  data: 2.6802  max mem: 21157
[10:23:18.644055] Test:  [19/20]  eta: 0:00:00  loss: 5.1150 (5.1118)  acc1: 2.3438 (2.4400)  acc5: 9.7656 (9.9000)  time: 0.2847  data: 0.1564  max mem: 21157
[10:23:18.753574] Test: Total time: 0:00:05 (0.2903 s / it)
[10:23:18.756465] * Acc@1 2.650 Acc@5 10.040 loss 5.116
[10:23:18.757003] Accuracy of the network on the 10000 test images: 2.7%
[10:23:18.757294] Max accuracy: 2.65%
[10:23:18.757541] Saving model at epoch: 2
[10:23:22.569968] Epoch: [3]  [  0/505]  eta: 0:29:48  lr: 0.000720  loss: 5.5914 (5.5914)  acc1: 1.9531 (1.9531)  acc5: 7.8125 (7.8125)  time: 3.5418  data: 2.9751  max mem: 21157
[10:24:10.014716] Epoch: [3]  [100/505]  eta: 0:03:24  lr: 0.000768  loss: 5.5234 (5.5427)  acc1: 1.9531 (1.9454)  acc5: 7.8125 (8.1451)  time: 0.4728  data: 0.0002  max mem: 21157
[10:24:57.339186] Epoch: [3]  [200/505]  eta: 0:02:29  lr: 0.000815  loss: 5.4889 (5.5240)  acc1: 1.9531 (2.1358)  acc5: 9.3750 (8.7201)  time: 0.4739  data: 0.0002  max mem: 21157
[10:25:44.705488] Epoch: [3]  [300/505]  eta: 0:01:39  lr: 0.000863  loss: 5.4599 (5.5089)  acc1: 2.7344 (2.2737)  acc5: 10.1562 (9.0596)  time: 0.4729  data: 0.0002  max mem: 21157
[10:26:32.027899] Epoch: [3]  [400/505]  eta: 0:00:50  lr: 0.000910  loss: 5.4220 (5.4919)  acc1: 2.7344 (2.4460)  acc5: 11.3281 (9.4948)  time: 0.4725  data: 0.0002  max mem: 21157
[10:27:19.232133] Epoch: [3]  [500/505]  eta: 0:00:02  lr: 0.000958  loss: 5.4020 (5.4743)  acc1: 3.1250 (2.6120)  acc5: 11.3281 (9.9808)  time: 0.4700  data: 0.0003  max mem: 21157
[10:27:21.162149] Epoch: [3]  [504/505]  eta: 0:00:00  lr: 0.000960  loss: 5.3854 (5.4734)  acc1: 3.1250 (2.6199)  acc5: 11.3281 (9.9969)  time: 0.4715  data: 0.0002  max mem: 21157
[10:27:21.299432] Epoch: [3] Total time: 0:04:02 (0.4797 s / it)
[10:27:21.301679] Averaged stats: lr: 0.000960  loss: 5.3854 (5.4744)  acc1: 3.1250 (2.6621)  acc5: 11.3281 (9.9625)
[10:27:21.302649] * Train_Acc@1 2.662 Acc@5 9.962 loss 5.474
[10:27:24.117649] Test:  [ 0/20]  eta: 0:00:56  loss: 4.8368 (4.8368)  acc1: 3.5156 (3.5156)  acc5: 16.7969 (16.7969)  time: 2.8110  data: 2.6320  max mem: 21157
[10:27:27.185347] Test:  [19/20]  eta: 0:00:00  loss: 4.8129 (4.8133)  acc1: 5.0781 (5.2600)  acc5: 17.9688 (17.8600)  time: 0.2939  data: 0.1667  max mem: 21157
[10:27:27.265605] Test: Total time: 0:00:05 (0.2980 s / it)
[10:27:27.268843] * Acc@1 5.250 Acc@5 18.150 loss 4.809
[10:27:27.269507] Accuracy of the network on the 10000 test images: 5.3%
[10:27:27.269842] Max accuracy: 5.25%
[10:27:27.270118] Saving model at epoch: 3
[10:27:30.462371] Epoch: [4]  [  0/505]  eta: 0:24:35  lr: 0.000960  loss: 5.3594 (5.3594)  acc1: 3.1250 (3.1250)  acc5: 12.8906 (12.8906)  time: 2.9226  data: 2.3657  max mem: 21157
[10:28:17.857256] Epoch: [4]  [100/505]  eta: 0:03:21  lr: 0.001008  loss: 5.3402 (5.3607)  acc1: 3.9062 (3.8676)  acc5: 13.6719 (13.3277)  time: 0.4747  data: 0.0002  max mem: 21157
[10:29:05.303576] Epoch: [4]  [200/505]  eta: 0:02:28  lr: 0.001055  loss: 5.2946 (5.3349)  acc1: 4.6875 (4.0714)  acc5: 15.2344 (14.1286)  time: 0.4733  data: 0.0002  max mem: 21157
[10:29:52.575992] Epoch: [4]  [300/505]  eta: 0:01:38  lr: 0.001103  loss: 5.2334 (5.3115)  acc1: 4.2969 (4.2047)  acc5: 16.4062 (14.6686)  time: 0.4728  data: 0.0002  max mem: 21157
[10:30:39.896568] Epoch: [4]  [400/505]  eta: 0:00:50  lr: 0.001150  loss: 5.1913 (5.2894)  acc1: 5.4688 (4.4128)  acc5: 17.5781 (15.2675)  time: 0.4730  data: 0.0002  max mem: 21157
[10:31:27.174904] Epoch: [4]  [500/505]  eta: 0:00:02  lr: 0.001198  loss: 5.1719 (5.2671)  acc1: 4.6875 (4.6158)  acc5: 19.1406 (15.7724)  time: 0.4696  data: 0.0003  max mem: 21157
[10:31:29.048961] Epoch: [4]  [504/505]  eta: 0:00:00  lr: 0.001200  loss: 5.1493 (5.2664)  acc1: 4.6875 (4.6295)  acc5: 19.1406 (15.7929)  time: 0.4689  data: 0.0002  max mem: 21157
[10:31:29.186282] Epoch: [4] Total time: 0:04:01 (0.4785 s / it)
[10:31:29.194761] Averaged stats: lr: 0.001200  loss: 5.1493 (5.2649)  acc1: 4.6875 (4.6898)  acc5: 19.1406 (15.7952)
[10:31:29.195483] * Train_Acc@1 4.690 Acc@5 15.795 loss 5.265
[10:31:31.920682] Test:  [ 0/20]  eta: 0:00:54  loss: 4.5746 (4.5746)  acc1: 6.6406 (6.6406)  acc5: 24.2188 (24.2188)  time: 2.7208  data: 2.5139  max mem: 21157
[10:31:35.067014] Test:  [19/20]  eta: 0:00:00  loss: 4.4746 (4.4860)  acc1: 8.5938 (8.4200)  acc5: 25.0000 (25.4200)  time: 0.2933  data: 0.1637  max mem: 21157
[10:31:35.149133] Test: Total time: 0:00:05 (0.2975 s / it)
[10:31:35.152500] * Acc@1 8.590 Acc@5 25.670 loss 4.481
[10:31:35.153331] Accuracy of the network on the 10000 test images: 8.6%
[10:31:35.153823] Max accuracy: 8.59%
[10:31:35.154226] Saving model at epoch: 4
[10:31:39.053099] Epoch: [5]  [  0/505]  eta: 0:30:38  lr: 0.001200  loss: 5.1835 (5.1835)  acc1: 3.9062 (3.9062)  acc5: 15.6250 (15.6250)  time: 3.6410  data: 3.0468  max mem: 21157
[10:32:26.377672] Epoch: [5]  [100/505]  eta: 0:03:24  lr: 0.001199  loss: 5.1183 (5.1301)  acc1: 5.4688 (6.2345)  acc5: 19.1406 (18.9395)  time: 0.4727  data: 0.0002  max mem: 21157
[10:33:13.732008] Epoch: [5]  [200/505]  eta: 0:02:29  lr: 0.001198  loss: 5.0773 (5.1067)  acc1: 6.2500 (6.4910)  acc5: 19.9219 (19.6051)  time: 0.4729  data: 0.0002  max mem: 21157
[10:34:01.046424] Epoch: [5]  [300/505]  eta: 0:01:39  lr: 0.001195  loss: 4.9912 (5.0824)  acc1: 7.8125 (6.7964)  acc5: 22.2656 (20.2256)  time: 0.4729  data: 0.0002  max mem: 21157
[10:34:48.395388] Epoch: [5]  [400/505]  eta: 0:00:50  lr: 0.001192  loss: 5.0072 (5.0630)  acc1: 7.0312 (7.0244)  acc5: 21.8750 (20.7470)  time: 0.4738  data: 0.0002  max mem: 21157
[10:35:35.624592] Epoch: [5]  [500/505]  eta: 0:00:02  lr: 0.001187  loss: 4.9319 (5.0422)  acc1: 8.2031 (7.2917)  acc5: 24.2188 (21.3838)  time: 0.4703  data: 0.0003  max mem: 21157
[10:35:37.497504] Epoch: [5]  [504/505]  eta: 0:00:00  lr: 0.001187  loss: 4.9267 (5.0414)  acc1: 8.5938 (7.3004)  acc5: 25.3906 (21.4070)  time: 0.4689  data: 0.0002  max mem: 21157
[10:35:37.638879] Epoch: [5] Total time: 0:04:02 (0.4797 s / it)
[10:35:37.654346] Averaged stats: lr: 0.001187  loss: 4.9267 (5.0420)  acc1: 8.5938 (7.2447)  acc5: 25.3906 (21.3765)
[10:35:37.654850] * Train_Acc@1 7.245 Acc@5 21.376 loss 5.042
[10:35:40.509591] Test:  [ 0/20]  eta: 0:00:57  loss: 4.3160 (4.3160)  acc1: 9.3750 (9.3750)  acc5: 30.4688 (30.4688)  time: 2.8514  data: 2.6505  max mem: 21157
[10:35:43.631496] Test:  [19/20]  eta: 0:00:00  loss: 4.1602 (4.1906)  acc1: 12.1094 (12.0000)  acc5: 32.0312 (32.5200)  time: 0.2986  data: 0.1700  max mem: 21157
[10:35:43.705965] Test: Total time: 0:00:06 (0.3024 s / it)
[10:35:43.709171] * Acc@1 12.010 Acc@5 32.710 loss 4.187
[10:35:43.709893] Accuracy of the network on the 10000 test images: 12.0%
[10:35:43.710259] Max accuracy: 12.01%
[10:35:43.710556] Saving model at epoch: 5
[10:35:47.284947] Epoch: [6]  [  0/505]  eta: 0:27:54  lr: 0.001187  loss: 4.9802 (4.9802)  acc1: 7.8125 (7.8125)  acc5: 24.6094 (24.6094)  time: 3.3152  data: 2.1866  max mem: 21157
[10:36:34.655965] Epoch: [6]  [100/505]  eta: 0:03:23  lr: 0.001181  loss: 4.9311 (4.9109)  acc1: 8.9844 (9.0037)  acc5: 23.4375 (24.8182)  time: 0.4726  data: 0.0002  max mem: 21157
[10:37:21.934227] Epoch: [6]  [200/505]  eta: 0:02:28  lr: 0.001175  loss: 4.8736 (4.8933)  acc1: 9.3750 (9.2409)  acc5: 25.7812 (25.4917)  time: 0.4759  data: 0.0002  max mem: 21157
[10:38:09.245397] Epoch: [6]  [300/505]  eta: 0:01:38  lr: 0.001167  loss: 4.8076 (4.8764)  acc1: 9.7656 (9.4632)  acc5: 26.5625 (25.7825)  time: 0.4730  data: 0.0002  max mem: 21157
[10:38:56.584383] Epoch: [6]  [400/505]  eta: 0:00:50  lr: 0.001158  loss: 4.7541 (4.8615)  acc1: 11.3281 (9.6633)  acc5: 29.6875 (26.2634)  time: 0.4750  data: 0.0002  max mem: 21157
[10:39:43.803212] Epoch: [6]  [500/505]  eta: 0:00:02  lr: 0.001149  loss: 4.7912 (4.8451)  acc1: 11.7188 (9.9387)  acc5: 28.1250 (26.7028)  time: 0.4710  data: 0.0003  max mem: 21157
[10:39:45.677888] Epoch: [6]  [504/505]  eta: 0:00:00  lr: 0.001148  loss: 4.7846 (4.8446)  acc1: 10.5469 (9.9420)  acc5: 28.1250 (26.7280)  time: 0.4699  data: 0.0002  max mem: 21157
[10:39:45.820077] Epoch: [6] Total time: 0:04:01 (0.4789 s / it)
[10:39:45.823107] Averaged stats: lr: 0.001148  loss: 4.7846 (4.8473)  acc1: 10.5469 (9.8677)  acc5: 28.1250 (26.7265)
[10:39:45.824428] * Train_Acc@1 9.868 Acc@5 26.726 loss 4.847
[10:39:49.467355] Test:  [ 0/20]  eta: 0:01:12  loss: 4.0616 (4.0616)  acc1: 12.8906 (12.8906)  acc5: 35.5469 (35.5469)  time: 3.6385  data: 3.4531  max mem: 21157
[10:39:52.147398] Test:  [19/20]  eta: 0:00:00  loss: 3.8841 (3.8977)  acc1: 15.2344 (15.6000)  acc5: 39.8438 (40.1000)  time: 0.3159  data: 0.1882  max mem: 21157
[10:39:52.211832] Test: Total time: 0:00:06 (0.3192 s / it)
[10:39:52.215005] * Acc@1 16.310 Acc@5 39.970 loss 3.887
[10:39:52.215793] Accuracy of the network on the 10000 test images: 16.3%
[10:39:52.216268] Max accuracy: 16.31%
[10:39:52.216655] Saving model at epoch: 6
[10:39:55.505142] Epoch: [7]  [  0/505]  eta: 0:25:26  lr: 0.001148  loss: 4.6221 (4.6221)  acc1: 13.2812 (13.2812)  acc5: 33.9844 (33.9844)  time: 3.0234  data: 2.4954  max mem: 21157
[10:40:42.772013] Epoch: [7]  [100/505]  eta: 0:03:21  lr: 0.001138  loss: 4.7127 (4.7388)  acc1: 11.3281 (11.4906)  acc5: 30.0781 (29.9312)  time: 0.4726  data: 0.0002  max mem: 21157
[10:41:30.074184] Epoch: [7]  [200/505]  eta: 0:02:28  lr: 0.001126  loss: 4.6787 (4.7239)  acc1: 11.7188 (11.6896)  acc5: 30.8594 (30.3638)  time: 0.4725  data: 0.0002  max mem: 21157
[10:42:17.482578] Epoch: [7]  [300/505]  eta: 0:01:38  lr: 0.001114  loss: 4.6983 (4.7150)  acc1: 12.8906 (11.8952)  acc5: 30.0781 (30.6439)  time: 0.4729  data: 0.0002  max mem: 21157
[10:43:04.809046] Epoch: [7]  [400/505]  eta: 0:00:50  lr: 0.001100  loss: 4.6252 (4.6987)  acc1: 13.2812 (12.1006)  acc5: 32.4219 (31.0951)  time: 0.4733  data: 0.0002  max mem: 21157
[10:43:52.180274] Epoch: [7]  [500/505]  eta: 0:00:02  lr: 0.001086  loss: 4.5987 (4.6814)  acc1: 13.2812 (12.3191)  acc5: 32.8125 (31.5104)  time: 0.4714  data: 0.0003  max mem: 21157
[10:43:54.061243] Epoch: [7]  [504/505]  eta: 0:00:00  lr: 0.001086  loss: 4.5987 (4.6808)  acc1: 13.2812 (12.3236)  acc5: 32.8125 (31.5261)  time: 0.4705  data: 0.0002  max mem: 21157
[10:43:54.203498] Epoch: [7] Total time: 0:04:01 (0.4787 s / it)
[10:43:54.206204] Averaged stats: lr: 0.001086  loss: 4.5987 (4.6808)  acc1: 13.2812 (12.2614)  acc5: 32.8125 (31.3834)
[10:43:54.206729] * Train_Acc@1 12.261 Acc@5 31.383 loss 4.681
[10:43:57.108076] Test:  [ 0/20]  eta: 0:00:57  loss: 3.8518 (3.8518)  acc1: 16.4062 (16.4062)  acc5: 42.1875 (42.1875)  time: 2.8979  data: 2.7176  max mem: 21157
[10:44:00.019165] Test:  [19/20]  eta: 0:00:00  loss: 3.7499 (3.7637)  acc1: 18.3594 (18.3800)  acc5: 42.9688 (43.1200)  time: 0.2904  data: 0.1627  max mem: 21157
[10:44:00.105080] Test: Total time: 0:00:05 (0.2948 s / it)
[10:44:00.108271] * Acc@1 18.880 Acc@5 43.390 loss 3.750
[10:44:00.108956] Accuracy of the network on the 10000 test images: 18.9%
[10:44:00.109356] Max accuracy: 18.88%
[10:44:00.109686] Saving model at epoch: 7
[10:44:03.809674] Epoch: [8]  [  0/505]  eta: 0:28:34  lr: 0.001086  loss: 4.6933 (4.6933)  acc1: 14.4531 (14.4531)  acc5: 32.0312 (32.0312)  time: 3.3960  data: 2.8479  max mem: 21157
[10:44:51.179566] Epoch: [8]  [100/505]  eta: 0:03:23  lr: 0.001070  loss: 4.5602 (4.5967)  acc1: 14.4531 (13.8072)  acc5: 32.4219 (33.4506)  time: 0.4725  data: 0.0002  max mem: 21157
[10:45:38.501372] Epoch: [8]  [200/505]  eta: 0:02:28  lr: 0.001055  loss: 4.5345 (4.5721)  acc1: 15.2344 (14.1636)  acc5: 35.9375 (34.2895)  time: 0.4741  data: 0.0002  max mem: 21157
[10:46:25.820185] Epoch: [8]  [300/505]  eta: 0:01:39  lr: 0.001038  loss: 4.5268 (4.5551)  acc1: 14.4531 (14.3908)  acc5: 34.3750 (34.8889)  time: 0.4733  data: 0.0002  max mem: 21157
[10:47:13.287917] Epoch: [8]  [400/505]  eta: 0:00:50  lr: 0.001021  loss: 4.4950 (4.5463)  acc1: 15.6250 (14.6080)  acc5: 37.1094 (35.1592)  time: 0.4735  data: 0.0002  max mem: 21157
[10:48:00.568912] Epoch: [8]  [500/505]  eta: 0:00:02  lr: 0.001003  loss: 4.4570 (4.5339)  acc1: 16.0156 (14.7556)  acc5: 36.7188 (35.4338)  time: 0.4703  data: 0.0003  max mem: 21157
[10:48:02.444009] Epoch: [8]  [504/505]  eta: 0:00:00  lr: 0.001002  loss: 4.4527 (4.5336)  acc1: 16.0156 (14.7494)  acc5: 36.7188 (35.4510)  time: 0.4693  data: 0.0002  max mem: 21157
[10:48:02.581486] Epoch: [8] Total time: 0:04:02 (0.4795 s / it)
[10:48:02.584801] Averaged stats: lr: 0.001002  loss: 4.4527 (4.5325)  acc1: 16.0156 (14.7683)  acc5: 36.7188 (35.5415)
[10:48:02.586134] * Train_Acc@1 14.768 Acc@5 35.541 loss 4.533
[10:48:05.285533] Test:  [ 0/20]  eta: 0:00:53  loss: 3.6102 (3.6102)  acc1: 22.2656 (22.2656)  acc5: 46.8750 (46.8750)  time: 2.6938  data: 2.5213  max mem: 21157
[10:48:08.220226] Test:  [19/20]  eta: 0:00:00  loss: 3.4846 (3.5124)  acc1: 22.2656 (22.8000)  acc5: 48.8281 (48.8400)  time: 0.2814  data: 0.1523  max mem: 21157
[10:48:08.297965] Test: Total time: 0:00:05 (0.2853 s / it)
[10:48:08.511983] * Acc@1 23.330 Acc@5 49.310 loss 3.487
[10:48:08.512333] Accuracy of the network on the 10000 test images: 23.3%
[10:48:08.512476] Max accuracy: 23.33%
[10:48:08.512596] Saving model at epoch: 8
[10:48:11.995525] Epoch: [9]  [  0/505]  eta: 0:27:12  lr: 0.001002  loss: 4.4080 (4.4080)  acc1: 18.3594 (18.3594)  acc5: 38.2812 (38.2812)  time: 3.2322  data: 2.6839  max mem: 21157
[10:48:59.263085] Epoch: [9]  [100/505]  eta: 0:03:22  lr: 0.000983  loss: 4.4578 (4.4579)  acc1: 16.0156 (16.0427)  acc5: 38.6719 (37.6006)  time: 0.4719  data: 0.0002  max mem: 21157
[10:49:46.652578] Epoch: [9]  [200/505]  eta: 0:02:28  lr: 0.000963  loss: 4.3823 (4.4356)  acc1: 17.5781 (16.4840)  acc5: 39.0625 (38.1161)  time: 0.4733  data: 0.0002  max mem: 21157
[10:50:33.996090] Epoch: [9]  [300/505]  eta: 0:01:38  lr: 0.000943  loss: 4.3761 (4.4276)  acc1: 17.5781 (16.6502)  acc5: 39.4531 (38.3267)  time: 0.4739  data: 0.0002  max mem: 21157
[10:51:21.327127] Epoch: [9]  [400/505]  eta: 0:00:50  lr: 0.000923  loss: 4.3500 (4.4132)  acc1: 17.9688 (16.9371)  acc5: 41.0156 (38.7440)  time: 0.4721  data: 0.0002  max mem: 21157
[10:52:08.686715] Epoch: [9]  [500/505]  eta: 0:00:02  lr: 0.000901  loss: 4.3297 (4.4030)  acc1: 18.7500 (17.0760)  acc5: 41.0156 (39.0391)  time: 0.4705  data: 0.0002  max mem: 21157
[10:52:10.562269] Epoch: [9]  [504/505]  eta: 0:00:00  lr: 0.000900  loss: 4.3079 (4.4021)  acc1: 18.7500 (17.0962)  acc5: 41.0156 (39.0656)  time: 0.4692  data: 0.0002  max mem: 21157
[10:52:10.703610] Epoch: [9] Total time: 0:04:01 (0.4791 s / it)
[10:52:10.706891] Averaged stats: lr: 0.000900  loss: 4.3079 (4.4048)  acc1: 18.7500 (17.0815)  acc5: 41.0156 (38.9890)
[10:52:10.707816] * Train_Acc@1 17.082 Acc@5 38.989 loss 4.405
[10:52:13.234979] Test:  [ 0/20]  eta: 0:00:50  loss: 3.4059 (3.4059)  acc1: 23.4375 (23.4375)  acc5: 49.6094 (49.6094)  time: 2.5221  data: 2.3365  max mem: 21157
[10:52:16.522212] Test:  [19/20]  eta: 0:00:00  loss: 3.2789 (3.2910)  acc1: 25.0000 (25.8000)  acc5: 53.5156 (53.3000)  time: 0.2904  data: 0.1599  max mem: 21157
[10:52:16.588087] Test: Total time: 0:00:05 (0.2938 s / it)
[10:52:16.591191] * Acc@1 26.250 Acc@5 53.600 loss 3.273
[10:52:16.591790] Accuracy of the network on the 10000 test images: 26.3%
[10:52:16.592133] Max accuracy: 26.25%
[10:52:16.592430] Saving model at epoch: 9
[10:52:20.279175] Epoch: [10]  [  0/505]  eta: 0:28:48  lr: 0.000900  loss: 4.3030 (4.3030)  acc1: 19.1406 (19.1406)  acc5: 41.7969 (41.7969)  time: 3.4237  data: 2.8874  max mem: 21157
[10:53:07.621956] Epoch: [10]  [100/505]  eta: 0:03:23  lr: 0.000878  loss: 4.3207 (4.3384)  acc1: 17.9688 (18.2047)  acc5: 41.4062 (40.7642)  time: 0.4730  data: 0.0002  max mem: 21157
[10:53:54.904017] Epoch: [10]  [200/505]  eta: 0:02:28  lr: 0.000856  loss: 4.2988 (4.3255)  acc1: 18.3594 (18.3341)  acc5: 41.4062 (41.1167)  time: 0.4740  data: 0.0002  max mem: 21157
[10:54:42.195431] Epoch: [10]  [300/505]  eta: 0:01:38  lr: 0.000834  loss: 4.2411 (4.3072)  acc1: 19.9219 (18.6267)  acc5: 43.3594 (41.5685)  time: 0.4740  data: 0.0002  max mem: 21157
[10:55:29.549196] Epoch: [10]  [400/505]  eta: 0:00:50  lr: 0.000810  loss: 4.2322 (4.2978)  acc1: 18.7500 (18.8299)  acc5: 41.7969 (41.7988)  time: 0.4730  data: 0.0002  max mem: 21157
[10:56:16.794081] Epoch: [10]  [500/505]  eta: 0:00:02  lr: 0.000787  loss: 4.2395 (4.2846)  acc1: 21.0938 (19.1367)  acc5: 42.9688 (42.1228)  time: 0.4700  data: 0.0003  max mem: 21157
[10:56:18.669710] Epoch: [10]  [504/505]  eta: 0:00:00  lr: 0.000786  loss: 4.2226 (4.2835)  acc1: 21.0938 (19.1638)  acc5: 42.9688 (42.1550)  time: 0.4689  data: 0.0002  max mem: 21157
[10:56:18.808811] Epoch: [10] Total time: 0:04:01 (0.4791 s / it)
[10:56:18.812423] Averaged stats: lr: 0.000786  loss: 4.2226 (4.2878)  acc1: 21.0938 (19.1526)  acc5: 42.9688 (42.0757)
[10:56:18.813548] * Train_Acc@1 19.153 Acc@5 42.076 loss 4.288
[10:56:21.683482] Test:  [ 0/20]  eta: 0:00:57  loss: 3.3227 (3.3227)  acc1: 29.2969 (29.2969)  acc5: 55.0781 (55.0781)  time: 2.8638  data: 2.6917  max mem: 21157
[10:56:24.359749] Test:  [19/20]  eta: 0:00:00  loss: 3.2682 (3.2618)  acc1: 26.9531 (26.6400)  acc5: 54.2969 (53.3800)  time: 0.2769  data: 0.1491  max mem: 21157
[10:56:24.445092] Test: Total time: 0:00:05 (0.2813 s / it)
[10:56:24.621435] * Acc@1 27.460 Acc@5 53.500 loss 3.244
[10:56:24.621783] Accuracy of the network on the 10000 test images: 27.5%
[10:56:24.621921] Max accuracy: 27.46%
[10:56:24.622023] Saving model at epoch: 10
[10:56:27.783401] Epoch: [11]  [  0/505]  eta: 0:24:00  lr: 0.000786  loss: 4.2310 (4.2310)  acc1: 21.8750 (21.8750)  acc5: 44.1406 (44.1406)  time: 2.8529  data: 2.1022  max mem: 21157
[10:57:15.252819] Epoch: [11]  [100/505]  eta: 0:03:21  lr: 0.000762  loss: 4.2780 (4.2402)  acc1: 19.5312 (19.9257)  acc5: 41.7969 (43.2820)  time: 0.4765  data: 0.0002  max mem: 21157
[10:58:02.537283] Epoch: [11]  [200/505]  eta: 0:02:28  lr: 0.000738  loss: 4.2070 (4.2166)  acc1: 22.2656 (20.3475)  acc5: 44.1406 (43.8064)  time: 0.4725  data: 0.0002  max mem: 21157
[10:58:49.782756] Epoch: [11]  [300/505]  eta: 0:01:38  lr: 0.000714  loss: 4.1699 (4.2076)  acc1: 20.7031 (20.5175)  acc5: 44.5312 (43.9966)  time: 0.4727  data: 0.0002  max mem: 21157
[10:59:37.052497] Epoch: [11]  [400/505]  eta: 0:00:50  lr: 0.000689  loss: 4.1375 (4.1996)  acc1: 21.4844 (20.7664)  acc5: 46.0938 (44.3130)  time: 0.4724  data: 0.0002  max mem: 21157
[11:00:24.182300] Epoch: [11]  [500/505]  eta: 0:00:02  lr: 0.000664  loss: 4.1886 (4.1928)  acc1: 21.4844 (20.9550)  acc5: 45.7031 (44.5328)  time: 0.4697  data: 0.0003  max mem: 21157
[11:00:26.056073] Epoch: [11]  [504/505]  eta: 0:00:00  lr: 0.000663  loss: 4.1579 (4.1928)  acc1: 21.8750 (20.9739)  acc5: 45.7031 (44.5297)  time: 0.4688  data: 0.0002  max mem: 21157
[11:00:26.207489] Epoch: [11] Total time: 0:04:01 (0.4778 s / it)
[11:00:26.211134] Averaged stats: lr: 0.000663  loss: 4.1579 (4.1936)  acc1: 21.8750 (20.9785)  acc5: 45.7031 (44.5320)
[11:00:26.212750] * Train_Acc@1 20.978 Acc@5 44.532 loss 4.194
[11:00:29.540176] Test:  [ 0/20]  eta: 0:01:06  loss: 3.1520 (3.1520)  acc1: 29.6875 (29.6875)  acc5: 58.9844 (58.9844)  time: 3.3224  data: 3.1371  max mem: 21157
[11:00:32.229532] Test:  [19/20]  eta: 0:00:00  loss: 3.0060 (3.0038)  acc1: 31.6406 (31.5400)  acc5: 59.7656 (59.9800)  time: 0.3005  data: 0.1716  max mem: 21157
[11:00:32.330999] Test: Total time: 0:00:06 (0.3057 s / it)
[11:00:32.340923] * Acc@1 32.090 Acc@5 60.420 loss 2.977
[11:00:32.341278] Accuracy of the network on the 10000 test images: 32.1%
[11:00:32.341456] Max accuracy: 32.09%
[11:00:32.341604] Saving model at epoch: 11
[11:00:35.324730] Epoch: [12]  [  0/505]  eta: 0:22:59  lr: 0.000663  loss: 4.1147 (4.1147)  acc1: 22.6562 (22.6562)  acc5: 49.6094 (49.6094)  time: 2.7311  data: 2.1630  max mem: 21157
[11:01:22.685336] Epoch: [12]  [100/505]  eta: 0:03:20  lr: 0.000638  loss: 4.0793 (4.1280)  acc1: 23.4375 (22.1032)  acc5: 48.0469 (46.2059)  time: 0.4722  data: 0.0002  max mem: 21157
[11:02:10.075681] Epoch: [12]  [200/505]  eta: 0:02:27  lr: 0.000614  loss: 4.1011 (4.1212)  acc1: 23.0469 (22.3803)  acc5: 47.2656 (46.1598)  time: 0.4753  data: 0.0002  max mem: 21157
[11:02:57.368398] Epoch: [12]  [300/505]  eta: 0:01:38  lr: 0.000589  loss: 4.1366 (4.1172)  acc1: 22.2656 (22.4097)  acc5: 45.3125 (46.2858)  time: 0.4722  data: 0.0002  max mem: 21157
[11:03:44.737916] Epoch: [12]  [400/505]  eta: 0:00:50  lr: 0.000564  loss: 4.0724 (4.1157)  acc1: 22.6562 (22.4049)  acc5: 46.8750 (46.4542)  time: 0.4739  data: 0.0002  max mem: 21157
[11:04:31.936551] Epoch: [12]  [500/505]  eta: 0:00:02  lr: 0.000539  loss: 4.0714 (4.1103)  acc1: 22.6562 (22.4683)  acc5: 46.0938 (46.5912)  time: 0.4696  data: 0.0002  max mem: 21157
[11:04:33.810162] Epoch: [12]  [504/505]  eta: 0:00:00  lr: 0.000538  loss: 4.0589 (4.1094)  acc1: 23.8281 (22.4892)  acc5: 46.8750 (46.6019)  time: 0.4689  data: 0.0002  max mem: 21157
[11:04:33.949586] Epoch: [12] Total time: 0:04:01 (0.4779 s / it)
[11:04:33.951970] Averaged stats: lr: 0.000538  loss: 4.0589 (4.1085)  acc1: 23.8281 (22.5661)  acc5: 46.8750 (46.6344)
[11:04:33.952485] * Train_Acc@1 22.566 Acc@5 46.634 loss 4.109
[11:04:36.582805] Test:  [ 0/20]  eta: 0:00:52  loss: 3.0116 (3.0116)  acc1: 31.2500 (31.2500)  acc5: 58.5938 (58.5938)  time: 2.6269  data: 2.4415  max mem: 21157
[11:04:39.639734] Test:  [19/20]  eta: 0:00:00  loss: 2.8947 (2.8782)  acc1: 33.2031 (33.6400)  acc5: 62.1094 (62.1800)  time: 0.2841  data: 0.1563  max mem: 21157
[11:04:39.705342] Test: Total time: 0:00:05 (0.2875 s / it)
[11:04:39.708588] * Acc@1 34.240 Acc@5 62.310 loss 2.869
[11:04:39.709178] Accuracy of the network on the 10000 test images: 34.2%
[11:04:39.709505] Max accuracy: 34.24%
[11:04:39.709797] Saving model at epoch: 12
[11:04:43.139335] Epoch: [13]  [  0/505]  eta: 0:26:53  lr: 0.000538  loss: 4.0246 (4.0246)  acc1: 23.8281 (23.8281)  acc5: 48.8281 (48.8281)  time: 3.1951  data: 2.6102  max mem: 21157
[11:05:30.467939] Epoch: [13]  [100/505]  eta: 0:03:22  lr: 0.000513  loss: 4.0237 (4.0598)  acc1: 22.6562 (23.6618)  acc5: 49.2188 (48.0662)  time: 0.4729  data: 0.0002  max mem: 21157
[11:06:17.806852] Epoch: [13]  [200/505]  eta: 0:02:28  lr: 0.000489  loss: 4.0359 (4.0569)  acc1: 23.0469 (23.6435)  acc5: 48.4375 (48.1382)  time: 0.4737  data: 0.0002  max mem: 21157
[11:07:05.305923] Epoch: [13]  [300/505]  eta: 0:01:38  lr: 0.000464  loss: 4.0277 (4.0515)  acc1: 23.8281 (23.7970)  acc5: 49.2188 (48.3350)  time: 0.4730  data: 0.0002  max mem: 21157
[11:07:52.589497] Epoch: [13]  [400/505]  eta: 0:00:50  lr: 0.000440  loss: 4.0354 (4.0416)  acc1: 23.4375 (23.9177)  acc5: 48.4375 (48.5505)  time: 0.4722  data: 0.0002  max mem: 21157
[11:08:39.878064] Epoch: [13]  [500/505]  eta: 0:00:02  lr: 0.000416  loss: 3.9688 (4.0346)  acc1: 26.5625 (24.0690)  acc5: 50.7812 (48.6597)  time: 0.4701  data: 0.0003  max mem: 21157
[11:08:41.754425] Epoch: [13]  [504/505]  eta: 0:00:00  lr: 0.000415  loss: 3.9796 (4.0345)  acc1: 26.1719 (24.0664)  acc5: 50.3906 (48.6580)  time: 0.4690  data: 0.0002  max mem: 21157
[11:08:41.890668] Epoch: [13] Total time: 0:04:01 (0.4791 s / it)
[11:08:41.897998] Averaged stats: lr: 0.000415  loss: 3.9796 (4.0361)  acc1: 26.1719 (24.0931)  acc5: 50.3906 (48.6173)
[11:08:41.898517] * Train_Acc@1 24.093 Acc@5 48.617 loss 4.036
[11:08:44.953723] Test:  [ 0/20]  eta: 0:01:01  loss: 2.9710 (2.9710)  acc1: 30.8594 (30.8594)  acc5: 61.3281 (61.3281)  time: 3.0518  data: 2.8664  max mem: 21157
[11:08:47.788055] Test:  [19/20]  eta: 0:00:00  loss: 2.8212 (2.8150)  acc1: 35.5469 (35.1200)  acc5: 63.6719 (63.8800)  time: 0.2942  data: 0.1659  max mem: 21157
[11:08:47.863240] Test: Total time: 0:00:05 (0.2981 s / it)
[11:08:47.866406] * Acc@1 36.210 Acc@5 63.990 loss 2.800
[11:08:47.867142] Accuracy of the network on the 10000 test images: 36.2%
[11:08:47.867570] Max accuracy: 36.21%
[11:08:47.867947] Saving model at epoch: 13
[11:08:51.214083] Epoch: [14]  [  0/505]  eta: 0:25:55  lr: 0.000415  loss: 4.1030 (4.1030)  acc1: 18.7500 (18.7500)  acc5: 46.4844 (46.4844)  time: 3.0809  data: 2.4986  max mem: 21157
[11:09:38.615437] Epoch: [14]  [100/505]  eta: 0:03:22  lr: 0.000392  loss: 3.9717 (3.9842)  acc1: 25.7812 (25.0774)  acc5: 51.5625 (49.9033)  time: 0.4740  data: 0.0002  max mem: 21157
[11:10:25.915825] Epoch: [14]  [200/505]  eta: 0:02:28  lr: 0.000369  loss: 3.9953 (3.9948)  acc1: 25.7812 (25.0505)  acc5: 49.6094 (49.7862)  time: 0.4735  data: 0.0002  max mem: 21157
[11:11:13.358476] Epoch: [14]  [300/505]  eta: 0:01:38  lr: 0.000346  loss: 3.9575 (3.9868)  acc1: 25.7812 (25.1415)  acc5: 50.3906 (49.9533)  time: 0.4768  data: 0.0002  max mem: 21157
[11:12:00.727594] Epoch: [14]  [400/505]  eta: 0:00:50  lr: 0.000324  loss: 3.9645 (3.9846)  acc1: 24.6094 (25.1598)  acc5: 49.6094 (49.9737)  time: 0.4726  data: 0.0002  max mem: 21157
[11:12:48.012255] Epoch: [14]  [500/505]  eta: 0:00:02  lr: 0.000302  loss: 3.9546 (3.9836)  acc1: 26.1719 (25.1770)  acc5: 49.2188 (50.0070)  time: 0.4706  data: 0.0002  max mem: 21157
[11:12:49.887351] Epoch: [14]  [504/505]  eta: 0:00:00  lr: 0.000301  loss: 3.9583 (3.9832)  acc1: 25.0000 (25.1903)  acc5: 48.8281 (50.0201)  time: 0.4696  data: 0.0002  max mem: 21157
[11:12:50.034853] Epoch: [14] Total time: 0:04:01 (0.4790 s / it)
[11:12:50.038416] Averaged stats: lr: 0.000301  loss: 3.9583 (3.9827)  acc1: 25.0000 (25.1837)  acc5: 48.8281 (49.9544)
[11:12:50.040047] * Train_Acc@1 25.184 Acc@5 49.954 loss 3.983
[11:12:52.758817] Test:  [ 0/20]  eta: 0:00:54  loss: 2.8860 (2.8860)  acc1: 33.5938 (33.5938)  acc5: 64.0625 (64.0625)  time: 2.7135  data: 2.5280  max mem: 21157
[11:12:55.686140] Test:  [19/20]  eta: 0:00:00  loss: 2.7052 (2.7255)  acc1: 35.5469 (36.8400)  acc5: 65.2344 (65.2200)  time: 0.2820  data: 0.1537  max mem: 21157
[11:12:55.749913] Test: Total time: 0:00:05 (0.2853 s / it)
[11:12:55.815487] * Acc@1 37.420 Acc@5 65.490 loss 2.715
[11:12:55.815832] Accuracy of the network on the 10000 test images: 37.4%
[11:12:55.815959] Max accuracy: 37.42%
[11:12:55.816051] Saving model at epoch: 14
[11:12:59.654127] Epoch: [15]  [  0/505]  eta: 0:29:57  lr: 0.000301  loss: 3.9669 (3.9669)  acc1: 26.9531 (26.9531)  acc5: 49.2188 (49.2188)  time: 3.5589  data: 2.9484  max mem: 21157
[11:13:47.030164] Epoch: [15]  [100/505]  eta: 0:03:24  lr: 0.000279  loss: 3.9751 (3.9578)  acc1: 25.0000 (25.5221)  acc5: 50.0000 (50.4680)  time: 0.4739  data: 0.0002  max mem: 21157
[11:14:34.364676] Epoch: [15]  [200/505]  eta: 0:02:29  lr: 0.000259  loss: 3.9491 (3.9490)  acc1: 25.3906 (25.6996)  acc5: 50.0000 (50.7521)  time: 0.4734  data: 0.0002  max mem: 21157
[11:15:21.658416] Epoch: [15]  [300/505]  eta: 0:01:39  lr: 0.000239  loss: 3.9255 (3.9468)  acc1: 26.5625 (25.8319)  acc5: 50.3906 (50.7929)  time: 0.4727  data: 0.0002  max mem: 21157
[11:16:09.001360] Epoch: [15]  [400/505]  eta: 0:00:50  lr: 0.000219  loss: 3.9352 (3.9481)  acc1: 25.7812 (25.8300)  acc5: 50.3906 (50.7735)  time: 0.4730  data: 0.0002  max mem: 21157
[11:16:56.318974] Epoch: [15]  [500/505]  eta: 0:00:02  lr: 0.000200  loss: 3.8994 (3.9405)  acc1: 26.1719 (25.9933)  acc5: 51.9531 (50.9551)  time: 0.4706  data: 0.0003  max mem: 21157
[11:16:58.194031] Epoch: [15]  [504/505]  eta: 0:00:00  lr: 0.000200  loss: 3.9056 (3.9401)  acc1: 26.1719 (25.9994)  acc5: 51.5625 (50.9692)  time: 0.4696  data: 0.0003  max mem: 21157
[11:16:58.359013] Epoch: [15] Total time: 0:04:02 (0.4797 s / it)
[11:16:58.362044] Averaged stats: lr: 0.000200  loss: 3.9056 (3.9377)  acc1: 26.1719 (26.1231)  acc5: 51.5625 (51.0528)
[11:16:58.363394] * Train_Acc@1 26.123 Acc@5 51.053 loss 3.938
[11:17:01.794025] Test:  [ 0/20]  eta: 0:01:08  loss: 2.8766 (2.8766)  acc1: 33.9844 (33.9844)  acc5: 62.1094 (62.1094)  time: 3.4264  data: 3.2410  max mem: 21157
[11:17:04.607813] Test:  [19/20]  eta: 0:00:00  loss: 2.6845 (2.6793)  acc1: 37.1094 (37.2600)  acc5: 66.4062 (66.3400)  time: 0.3120  data: 0.1843  max mem: 21157
[11:17:04.689679] Test: Total time: 0:00:06 (0.3161 s / it)
[11:17:04.693033] * Acc@1 37.850 Acc@5 66.630 loss 2.671
[11:17:04.693778] Accuracy of the network on the 10000 test images: 37.9%
[11:17:04.694081] Max accuracy: 37.85%
[11:17:04.694341] Saving model at epoch: 15
[11:17:08.338776] Epoch: [16]  [  0/505]  eta: 0:28:26  lr: 0.000199  loss: 3.9226 (3.9226)  acc1: 26.5625 (26.5625)  acc5: 53.1250 (53.1250)  time: 3.3788  data: 2.8187  max mem: 21157
[11:17:55.677599] Epoch: [16]  [100/505]  eta: 0:03:23  lr: 0.000181  loss: 3.9133 (3.9177)  acc1: 26.5625 (26.3150)  acc5: 50.7812 (51.5277)  time: 0.4738  data: 0.0002  max mem: 21157
[11:18:43.017113] Epoch: [16]  [200/505]  eta: 0:02:28  lr: 0.000164  loss: 3.9121 (3.9179)  acc1: 25.7812 (26.1505)  acc5: 51.9531 (51.6558)  time: 0.4732  data: 0.0002  max mem: 21157
[11:19:30.351990] Epoch: [16]  [300/505]  eta: 0:01:39  lr: 0.000147  loss: 3.8997 (3.9126)  acc1: 25.7812 (26.3562)  acc5: 51.9531 (51.8272)  time: 0.4729  data: 0.0002  max mem: 21157
[11:20:17.657851] Epoch: [16]  [400/505]  eta: 0:00:50  lr: 0.000131  loss: 3.8886 (3.9091)  acc1: 25.7812 (26.5430)  acc5: 53.1250 (51.9268)  time: 0.4732  data: 0.0002  max mem: 21157
[11:21:04.885511] Epoch: [16]  [500/505]  eta: 0:00:02  lr: 0.000116  loss: 3.8547 (3.9060)  acc1: 27.7344 (26.6654)  acc5: 53.5156 (52.0225)  time: 0.4702  data: 0.0002  max mem: 21157
[11:21:06.761183] Epoch: [16]  [504/505]  eta: 0:00:00  lr: 0.000116  loss: 3.8554 (3.9058)  acc1: 27.3438 (26.6700)  acc5: 53.5156 (52.0367)  time: 0.4695  data: 0.0002  max mem: 21157
[11:21:06.910361] Epoch: [16] Total time: 0:04:01 (0.4791 s / it)
[11:21:06.927490] Averaged stats: lr: 0.000116  loss: 3.8554 (3.9031)  acc1: 27.3438 (26.7350)  acc5: 53.5156 (52.0247)
[11:21:06.927988] * Train_Acc@1 26.735 Acc@5 52.025 loss 3.903
[11:21:09.845631] Test:  [ 0/20]  eta: 0:00:58  loss: 2.8538 (2.8538)  acc1: 36.3281 (36.3281)  acc5: 62.8906 (62.8906)  time: 2.9143  data: 2.7310  max mem: 21157
[11:21:12.989683] Test:  [19/20]  eta: 0:00:00  loss: 2.6271 (2.6449)  acc1: 38.2812 (38.6200)  acc5: 67.5781 (67.4200)  time: 0.3029  data: 0.1753  max mem: 21157
[11:21:13.069289] Test: Total time: 0:00:06 (0.3069 s / it)
[11:21:13.072660] * Acc@1 38.830 Acc@5 67.180 loss 2.635
[11:21:13.073493] Accuracy of the network on the 10000 test images: 38.8%
[11:21:13.073992] Max accuracy: 38.83%
[11:21:13.074394] Saving model at epoch: 16
[11:21:17.189913] Epoch: [17]  [  0/505]  eta: 0:32:45  lr: 0.000115  loss: 4.0012 (4.0012)  acc1: 24.2188 (24.2188)  acc5: 50.3906 (50.3906)  time: 3.8922  data: 3.3379  max mem: 21157
[11:22:04.616161] Epoch: [17]  [100/505]  eta: 0:03:25  lr: 0.000101  loss: 3.8821 (3.8995)  acc1: 27.3438 (26.8332)  acc5: 51.5625 (51.9686)  time: 0.4734  data: 0.0002  max mem: 21157
[11:22:51.896323] Epoch: [17]  [200/505]  eta: 0:02:29  lr: 0.000088  loss: 3.8738 (3.8956)  acc1: 26.9531 (26.9745)  acc5: 53.1250 (52.2446)  time: 0.4728  data: 0.0002  max mem: 21157
[11:23:39.241818] Epoch: [17]  [300/505]  eta: 0:01:39  lr: 0.000076  loss: 3.8693 (3.8921)  acc1: 26.9531 (27.0985)  acc5: 52.3438 (52.2866)  time: 0.4729  data: 0.0002  max mem: 21157
[11:24:26.621630] Epoch: [17]  [400/505]  eta: 0:00:50  lr: 0.000064  loss: 3.8559 (3.8870)  acc1: 26.9531 (27.1168)  acc5: 52.7344 (52.3856)  time: 0.4736  data: 0.0002  max mem: 21157
[11:25:13.912281] Epoch: [17]  [500/505]  eta: 0:00:02  lr: 0.000053  loss: 3.8339 (3.8849)  acc1: 26.5625 (27.1192)  acc5: 52.3438 (52.3632)  time: 0.4702  data: 0.0003  max mem: 21157
[11:25:15.787467] Epoch: [17]  [504/505]  eta: 0:00:00  lr: 0.000053  loss: 3.8479 (3.8848)  acc1: 26.5625 (27.1248)  acc5: 51.5625 (52.3639)  time: 0.4695  data: 0.0002  max mem: 21157
[11:25:15.925468] Epoch: [17] Total time: 0:04:02 (0.4805 s / it)
[11:25:15.928796] Averaged stats: lr: 0.000053  loss: 3.8479 (3.8862)  acc1: 26.5625 (27.1229)  acc5: 51.5625 (52.3499)
[11:25:15.930245] * Train_Acc@1 27.123 Acc@5 52.350 loss 3.886
[11:25:18.800864] Test:  [ 0/20]  eta: 0:00:57  loss: 2.8427 (2.8427)  acc1: 35.1562 (35.1562)  acc5: 63.6719 (63.6719)  time: 2.8658  data: 2.6803  max mem: 21157
[11:25:21.726777] Test:  [19/20]  eta: 0:00:00  loss: 2.6192 (2.6184)  acc1: 38.6719 (39.0200)  acc5: 67.1875 (67.6000)  time: 0.2895  data: 0.1601  max mem: 21157
[11:25:21.814117] Test: Total time: 0:00:05 (0.2940 s / it)
[11:25:21.815520] * Acc@1 39.520 Acc@5 67.600 loss 2.612
[11:25:21.815861] Accuracy of the network on the 10000 test images: 39.5%
[11:25:21.816020] Max accuracy: 39.52%
[11:25:21.816142] Saving model at epoch: 17
[11:25:24.973796] Epoch: [18]  [  0/505]  eta: 0:24:19  lr: 0.000053  loss: 3.8099 (3.8099)  acc1: 31.2500 (31.2500)  acc5: 54.6875 (54.6875)  time: 2.8897  data: 2.1368  max mem: 21157
[11:26:12.602230] Epoch: [18]  [100/505]  eta: 0:03:22  lr: 0.000043  loss: 3.8484 (3.8821)  acc1: 25.7812 (27.1852)  acc5: 52.3438 (52.1929)  time: 0.4734  data: 0.0002  max mem: 21157
[11:26:59.984152] Epoch: [18]  [200/505]  eta: 0:02:28  lr: 0.000035  loss: 3.8902 (3.8757)  acc1: 28.1250 (27.4312)  acc5: 51.9531 (52.6158)  time: 0.4723  data: 0.0002  max mem: 21157
[11:27:47.311603] Epoch: [18]  [300/505]  eta: 0:01:38  lr: 0.000027  loss: 3.8779 (3.8785)  acc1: 26.5625 (27.4203)  acc5: 51.5625 (52.5449)  time: 0.4725  data: 0.0002  max mem: 21157
[11:28:34.671425] Epoch: [18]  [400/505]  eta: 0:00:50  lr: 0.000020  loss: 3.8607 (3.8785)  acc1: 27.3438 (27.3496)  acc5: 51.9531 (52.5162)  time: 0.4719  data: 0.0002  max mem: 21157
[11:29:21.921794] Epoch: [18]  [500/505]  eta: 0:00:02  lr: 0.000014  loss: 3.8633 (3.8777)  acc1: 26.5625 (27.3859)  acc5: 51.9531 (52.5722)  time: 0.4699  data: 0.0003  max mem: 21157
[11:29:23.796265] Epoch: [18]  [504/505]  eta: 0:00:00  lr: 0.000014  loss: 3.8174 (3.8772)  acc1: 27.7344 (27.4010)  acc5: 52.3438 (52.5882)  time: 0.4691  data: 0.0002  max mem: 21157
[11:29:23.934121] Epoch: [18] Total time: 0:04:01 (0.4789 s / it)
[11:29:23.937778] Averaged stats: lr: 0.000014  loss: 3.8174 (3.8748)  acc1: 27.7344 (27.4157)  acc5: 52.3438 (52.6183)
[11:29:23.938277] * Train_Acc@1 27.416 Acc@5 52.618 loss 3.875
[11:29:27.784045] Test:  [ 0/20]  eta: 0:01:16  loss: 2.7969 (2.7969)  acc1: 35.1562 (35.1562)  acc5: 63.2812 (63.2812)  time: 3.8425  data: 3.6693  max mem: 21157
[11:29:30.397910] Test:  [19/20]  eta: 0:00:00  loss: 2.6172 (2.6069)  acc1: 39.0625 (39.0800)  acc5: 67.5781 (68.0000)  time: 0.3228  data: 0.1947  max mem: 21157
[11:29:30.473504] Test: Total time: 0:00:06 (0.3266 s / it)
[11:29:30.476782] * Acc@1 39.540 Acc@5 67.790 loss 2.602
[11:29:30.477574] Accuracy of the network on the 10000 test images: 39.5%
[11:29:30.478085] Max accuracy: 39.54%
[11:29:30.478320] Saving model at epoch: 18
[11:29:34.025489] Epoch: [19]  [  0/505]  eta: 0:27:37  lr: 0.000014  loss: 3.8852 (3.8852)  acc1: 26.1719 (26.1719)  acc5: 54.6875 (54.6875)  time: 3.2824  data: 2.6934  max mem: 21157
[11:30:21.358349] Epoch: [19]  [100/505]  eta: 0:03:22  lr: 0.000009  loss: 3.8596 (3.8676)  acc1: 26.5625 (27.7228)  acc5: 51.9531 (52.9664)  time: 0.4725  data: 0.0002  max mem: 21157
[11:31:08.752607] Epoch: [19]  [200/505]  eta: 0:02:28  lr: 0.000006  loss: 3.8862 (3.8608)  acc1: 28.1250 (27.8996)  acc5: 52.3438 (52.9948)  time: 0.4730  data: 0.0002  max mem: 21157
[11:31:56.243471] Epoch: [19]  [300/505]  eta: 0:01:39  lr: 0.000003  loss: 3.8742 (3.8643)  acc1: 26.9531 (27.7201)  acc5: 53.5156 (52.9096)  time: 0.4747  data: 0.0002  max mem: 21157
[11:32:43.598468] Epoch: [19]  [400/505]  eta: 0:00:50  lr: 0.000002  loss: 3.8287 (3.8636)  acc1: 28.5156 (27.8474)  acc5: 53.9062 (52.9292)  time: 0.4741  data: 0.0002  max mem: 21157
[11:33:30.867283] Epoch: [19]  [500/505]  eta: 0:00:02  lr: 0.000001  loss: 3.9009 (3.8662)  acc1: 26.9531 (27.7391)  acc5: 51.5625 (52.8739)  time: 0.4692  data: 0.0003  max mem: 21157
[11:33:32.738978] Epoch: [19]  [504/505]  eta: 0:00:00  lr: 0.000001  loss: 3.8816 (3.8656)  acc1: 27.3438 (27.7491)  acc5: 51.9531 (52.8960)  time: 0.4686  data: 0.0002  max mem: 21157
[11:33:32.879162] Epoch: [19] Total time: 0:04:02 (0.4795 s / it)
[11:33:32.888315] Averaged stats: lr: 0.000001  loss: 3.8816 (3.8668)  acc1: 27.3438 (27.5866)  acc5: 51.9531 (52.9382)
[11:33:32.889081] * Train_Acc@1 27.587 Acc@5 52.938 loss 3.867
[11:33:32.890206] Saving model at epoch: 19
[11:33:36.166442] Test:  [ 0/20]  eta: 0:01:00  loss: 2.8390 (2.8390)  acc1: 33.5938 (33.5938)  acc5: 64.4531 (64.4531)  time: 3.0230  data: 2.8466  max mem: 21157
[11:33:39.066905] Test:  [19/20]  eta: 0:00:00  loss: 2.6251 (2.6156)  acc1: 38.2812 (38.6600)  acc5: 67.9688 (67.6000)  time: 0.2961  data: 0.1688  max mem: 21157
[11:33:39.150962] Test: Total time: 0:00:06 (0.3004 s / it)
[11:33:39.154324] * Acc@1 39.150 Acc@5 67.580 loss 2.608
[11:33:39.155140] Accuracy of the network on the 10000 test images: 39.1%
[11:33:39.155627] Max accuracy: 39.54%
[11:33:39.156044] Saving model at epoch: 19
[11:33:39.410773] Training time 1:22:51
