+ source /home4/p315895/venvs/lisnn/bin/activate
++ deactivate nondestructive
++ '[' -n '' ']'
++ '[' -n '' ']'
++ '[' -n /bin/bash -o -n '' ']'
++ hash -r
++ '[' -n '' ']'
++ unset VIRTUAL_ENV
++ unset VIRTUAL_ENV_PROMPT
++ '[' '!' nondestructive = nondestructive ']'
++ VIRTUAL_ENV=/home4/p315895/venvs/lisnn
++ export VIRTUAL_ENV
++ _OLD_VIRTUAL_PATH=/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
++ PATH=/home4/p315895/venvs/lisnn/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
++ export PATH
++ '[' -n '' ']'
++ '[' -z '' ']'
++ _OLD_VIRTUAL_PS1=
++ PS1='(lisnn) '
++ export PS1
++ VIRTUAL_ENV_PROMPT='(lisnn) '
++ export VIRTUAL_ENV_PROMPT
++ '[' -n /bin/bash -o -n '' ']'
++ hash -r
+ BASE_PORT=12346
+ export MASTER_PORT=12346
+ MASTER_PORT=12346
/var/spool/slurmd/job16709213/slurm_script: line 21: 1 * : syntax error: operand expected (error token is "* ")
++ head -n 1
++ scontrol show hostnames a100gpu1
+ export MASTER_ADDR=a100gpu1
+ MASTER_ADDR=a100gpu1
+ export OMP_NUM_THREADS=8
+ OMP_NUM_THREADS=8
+ echo MASTER_ADDR=a100gpu1
MASTER_ADDR=a100gpu1
+ echo WORLD_SIZE=
WORLD_SIZE=
++ date +%Y%m%d_%H%M%S
+ TIMESTAMP=20250420_094054
+ SEED=32
++ openssl rand -hex 4
+ SESSION_ID=f53da6e6
+ TRAIN_SCRIPT=/home4/p315895/Spike-Driven-Transformer-V3/SDT_V3/Classification/Model_Base/main_finetune.py
+ DATASET_NAME=ImageNet-200
+ DATASET_DIR=/tmp/dataset/ImageNet-200
+ mkdir -p /tmp/dataset
+ SECONDS=0
+ echo 'Extracting ImageNet-200.tar'
Extracting ImageNet-200.tar
+ tar -xf /scratch/p315895/datasets/ImageNet-200.tar -C /tmp/dataset
+ echo 'Time taken to extract dataset: 29 seconds'
Time taken to extract dataset: 29 seconds
+ COMMON_ARGS='--batch_size 256   --blr 6e-4   --warmup_epochs 5   --epochs 20   --model Efficient_Spiking_Transformer_s   --data_path /tmp/dataset/ImageNet-200   --output_dir outputs/T1   --log_dir outputs/T1   --model_mode ms   --dist_eval '
+ EXPERIMENT_NAME=ImageNet-200_20250420_094054_s32
+ case ${SLURM_ARRAY_TASK_ID} in
+ torchrun --standalone --nproc_per_node=2 /home4/p315895/Spike-Driven-Transformer-V3/SDT_V3/Classification/Model_Base/main_finetune.py --batch_size 256 --blr 6e-4 --warmup_epochs 5 --epochs 20 --model Efficient_Spiking_Transformer_s --data_path /tmp/dataset/ImageNet-200 --output_dir outputs/T1 --log_dir outputs/T1 --model_mode ms --dist_eval --name ImageNet-200_20250420_094054_s32 --wandb_tags small li ImageNet-200 --lateral_inhibition --trainable_threshold
/home4/p315895/venvs/lisnn/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home4/p315895/venvs/lisnn/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
| distributed init (rank 0): env://, gpu 0
[rank0]:[W420 09:41:45.512647607 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
| distributed init (rank 1): env://, gpu 1
[rank1]:[W420 09:41:45.528188192 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[09:41:45.870980] job dir: /home4/p315895/Spike-Driven-Transformer-V3/SDT_V3/Classification/Model_Base
[09:41:45.871242] Namespace(batch_size=256,
epochs=20,
accum_iter=1,
finetune='',
data_path='/tmp/dataset/ImageNet-200',
model='Efficient_Spiking_Transformer_s',
model_mode='ms',
input_size=224,
drop_path=0.1,
clip_grad=None,
weight_decay=0.05,
lr=None,
blr=0.0006,
layer_decay=1.0,
min_lr=1e-06,
warmup_epochs=5,
color_jitter=None,
aa='rand-m9-mstd0.5-inc1',
smoothing=0.1,
reprob=0.25,
remode='pixel',
recount=1,
resplit=False,
mixup=0,
cutmix=0,
cutmix_minmax=None,
mixup_prob=1.0,
mixup_switch_prob=0.5,
mixup_mode='batch',
global_pool=True,
time_steps=1,
nb_classes=1000,
output_dir='outputs/T1',
log_dir='outputs/T1',
device='cuda',
seed=0,
resume=None,
start_epoch=0,
eval=False,
repeated_aug=False,
dist_eval=True,
num_workers=10,
pin_mem=True,
world_size=2,
local_rank=-1,
dist_on_itp=False,
dist_url='env://',
wandb=True,
name='ImageNet-200_20250420_094054_s32',
wandb_tags=['small',
'li',
'ImageNet-200'],
lateral_inhibition=True,
trainable_threshold=True,
rank=0,
gpu=0,
distributed=True,
dist_backend='nccl')
[09:41:46.296332] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f3dd54fa950>
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.
wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.
wandb: Appending key for api.wandb.ai to your netrc file: /home4/p315895/.netrc
wandb: Currently logged in as: prdvanderwal to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Ignoring ID e163hryo loaded due to resume='auto' because the run ID is set to zmzir6ef.
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in /home4/p315895/Spike-Driven-Transformer-V3/SDT_V3/Classification/Model_Base/wandb/run-20250420_094147-zmzir6ef
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run li_True-blr_0.0006-b_256
wandb: 救넖잺 View project at https://wandb.ai/prdvanderwal/LIT
wandb: 游 View run at https://wandb.ai/prdvanderwal/LIT/runs/zmzir6ef
[09:41:48.645253] Model = Spiking_vit_MetaFormer_Spike_SepConv(
  (downsample1_1): MS_DownSampling(
    (encode_conv): Conv2d(3, 16, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))
    (encode_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (ConvBlock1_1): ModuleList(
    (0): MS_ConvBlock_spike_SepConv(
      (Conv): SepConv_Spike(
        (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv1): Sequential(
          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (dwconv): Sequential(
          (0): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32, bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike3): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv2): Sequential(
          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      (conv1): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      (conv2): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (downsample1_2): MS_DownSampling(
    (encode_conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (encode_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (encode_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
  )
  (ConvBlock1_2): ModuleList(
    (0): MS_ConvBlock_spike_SepConv(
      (Conv): SepConv_Spike(
        (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv1): Sequential(
          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (dwconv): Sequential(
          (0): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64, bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike3): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv2): Sequential(
          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      (conv1): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (downsample2): MS_DownSampling(
    (encode_conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (encode_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (encode_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
  )
  (ConvBlock2_1): ModuleList(
    (0): MS_ConvBlock_spike_SepConv(
      (Conv): SepConv_Spike(
        (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv1): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (dwconv): Sequential(
          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike3): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv2): Sequential(
          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      (conv1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      (conv2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (ConvBlock2_2): ModuleList(
    (0): MS_ConvBlock_spike_SepConv(
      (Conv): SepConv_Spike(
        (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv1): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (dwconv): Sequential(
          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike3): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv2): Sequential(
          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      (conv1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      (conv2): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (downsample3): MS_DownSampling(
    (encode_conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    (encode_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (encode_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
  )
  (block3): ModuleList(
    (0-5): 6 x MS_Block_Spike_SepConv(
      (conv): SepConv_Spike(
        (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv1): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (dwconv): Sequential(
          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike3): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv2): Sequential(
          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (attn): MS_Attention_linear_with_LateralInhibition(
        (head_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (qe_conv): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (qe_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (qi_conv): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (qi_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (k_conv): Sequential(
          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (k_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (v_conv): Sequential(
          (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (v_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (attn_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (excitatory_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (inhibitory_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (combined_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (proj_conv): Sequential(
          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (drop_path): Identity()
      (mlp): MS_MLP(
        (fc1_conv): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
        (fc1_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (fc1_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (fc2_conv): Conv1d(512, 128, kernel_size=(1,), stride=(1,))
        (fc2_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (fc2_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      )
    )
  )
  (downsample4): MS_DownSampling(
    (encode_conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (encode_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (encode_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
  )
  (block4): ModuleList(
    (0-1): 2 x MS_Block_Spike_SepConv(
      (conv): SepConv_Spike(
        (spike1): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv1): Sequential(
          (0): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike2): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (dwconv): Sequential(
          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (spike3): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (pwconv2): Sequential(
          (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (attn): MS_Attention_linear_with_LateralInhibition(
        (head_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (qe_conv): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (qe_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (qi_conv): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (qi_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (k_conv): Sequential(
          (0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (k_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (v_conv): Sequential(
          (0): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (v_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (attn_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (excitatory_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (inhibitory_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (combined_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (proj_conv): Sequential(
          (0): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (drop_path): Identity()
      (mlp): MS_MLP(
        (fc1_conv): Conv1d(192, 768, kernel_size=(1,), stride=(1,))
        (fc1_bn): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (fc1_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
        (fc2_conv): Conv1d(768, 192, kernel_size=(1,), stride=(1,))
        (fc2_bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (fc2_spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=4, Threshold=0.5000)
      )
    )
  )
  (head): Linear(in_features=192, out_features=1000, bias=True)
  (spike): MultiSpike(Max_Value=4, Min_Value=0, Norm=1, Threshold=0.5000)
)
[09:41:48.645609] number of params (M): 5.28
[09:41:48.645752] base lr: 6.00e-04
[09:41:48.645848] actual lr: 1.20e-03
[09:41:48.645930] accumulate grad iterations: 1
[09:41:48.646013] effective batch size: 512
[09:41:48.711144] criterion = LabelSmoothingCrossEntropy()
[09:41:48.711425] Start training for 20 epochs
[09:42:01.148561] Epoch: [0]  [  0/505]  eta: 1:44:37  lr: 0.000000  loss: 6.9106 (6.9106)  acc1: 0.3906 (0.3906)  acc5: 2.3438 (2.3438)  time: 12.4310  data: 5.2368  max mem: 19949
[09:42:48.347432] Epoch: [0]  [100/505]  eta: 0:03:59  lr: 0.000048  loss: 6.9040 (6.9069)  acc1: 0.3906 (0.3636)  acc5: 1.5625 (1.5625)  time: 0.4681  data: 0.0006  max mem: 19949
[09:43:35.166148] Epoch: [0]  [200/505]  eta: 0:02:41  lr: 0.000095  loss: 6.8841 (6.9001)  acc1: 0.0000 (0.3731)  acc5: 1.9531 (1.7141)  time: 0.4688  data: 0.0006  max mem: 19949
[09:44:22.524498] Epoch: [0]  [300/505]  eta: 0:01:44  lr: 0.000143  loss: 6.8417 (6.8871)  acc1: 0.3906 (0.4101)  acc5: 2.7344 (1.9259)  time: 0.4696  data: 0.0006  max mem: 19949
[09:45:09.521743] Epoch: [0]  [400/505]  eta: 0:00:52  lr: 0.000190  loss: 6.7761 (6.8667)  acc1: 0.3906 (0.4247)  acc5: 3.1250 (2.0895)  time: 0.4692  data: 0.0006  max mem: 19949
[09:45:56.391555] Epoch: [0]  [500/505]  eta: 0:00:02  lr: 0.000238  loss: 6.6699 (6.8370)  acc1: 0.3906 (0.4444)  acc5: 2.7344 (2.2229)  time: 0.4673  data: 0.0004  max mem: 19949
[09:45:58.254887] Epoch: [0]  [504/505]  eta: 0:00:00  lr: 0.000240  loss: 6.6730 (6.8357)  acc1: 0.3906 (0.4455)  acc5: 2.3438 (2.2215)  time: 0.4663  data: 0.0002  max mem: 19949
[09:45:58.382010] Epoch: [0] Total time: 0:04:09 (0.4944 s / it)
[09:45:58.385079] Averaged stats: lr: 0.000240  loss: 6.6730 (6.8356)  acc1: 0.3906 (0.4544)  acc5: 2.3438 (2.2660)
[09:45:58.386315] * Train_Acc@1 0.454 Acc@5 2.266 loss 6.836
[09:45:58.387593] Saving model at epoch: 0
wandb: WARNING Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[09:46:02.735845] Test:  [ 0/20]  eta: 0:01:21  loss: 6.6193 (6.6193)  acc1: 1.1719 (1.1719)  acc5: 3.5156 (3.5156)  time: 4.0849  data: 3.8921  max mem: 19949
[09:46:05.678438] Test:  [19/20]  eta: 0:00:00  loss: 6.6135 (6.6103)  acc1: 0.7812 (0.7000)  acc5: 3.5156 (3.6000)  time: 0.3513  data: 0.2013  max mem: 19949
[09:46:05.748469] Test: Total time: 0:00:07 (0.3549 s / it)
[09:46:05.751861] * Acc@1 0.640 Acc@5 3.350 loss 6.615
[09:46:05.752627] Accuracy of the network on the 10000 test images: 0.6%
[09:46:05.752962] Max accuracy: 0.64%
[09:46:05.753196] Saving model at epoch: 0
[09:46:09.279102] Epoch: [1]  [  0/505]  eta: 0:27:32  lr: 0.000240  loss: 6.6533 (6.6533)  acc1: 0.3906 (0.3906)  acc5: 3.1250 (3.1250)  time: 3.2718  data: 2.1005  max mem: 19949
[09:46:56.348657] Epoch: [1]  [100/505]  eta: 0:03:21  lr: 0.000288  loss: 6.4993 (6.5721)  acc1: 0.3906 (0.6304)  acc5: 3.1250 (3.2294)  time: 0.4695  data: 0.0005  max mem: 19949
[09:47:43.341882] Epoch: [1]  [200/505]  eta: 0:02:27  lr: 0.000335  loss: 6.2789 (6.4754)  acc1: 0.7812 (0.6957)  acc5: 3.5156 (3.2435)  time: 0.4694  data: 0.0005  max mem: 19949
slurmstepd: error: *** JOB 16709213 ON a100gpu1 CANCELLED AT 2025-04-20T09:48:17 ***

###############################################################################
H치br칩k Cluster
Job 16709213_0 for user p315895
Finished at: Sun Apr 20 09:48:26 CEST 2025

Job details:
============

Job ID                         : 16709213_0
Name                           : LISNN_IN200_li
User                           : p315895
Partition                      : gpushort
Nodes                          : a100gpu1
Number of Nodes                : 1
Cores                          : 16
Number of Tasks                : 1
State                          : CANCELLED by user  
Submit                         : 2025-04-20T09:40:51
Start                          : 2025-04-20T09:40:52
End                            : 2025-04-20T09:48:21
Reserved walltime              : 04:00:00
Used walltime                  : 00:07:29
Used CPU time                  : 00:55:53 (Efficiency: 46.68%)
% User (Computation)           : 89.76%
% System (I/O)                 : 10.24%
Total memory reserved          : 48G
Maximum memory used            : 9.83G
Requested GPUs                 : a100=2
Allocated GPUs                 : a100=2
Max GPU utilization            : 182%
Max GPU memory used            : 43.21G
Hints and tips      :
 1) You requested much more CPU memory than your program used.
    Please reduce the requested amount of memory.
 *) For more information on these issues see:
    https://wiki.hpc.rug.nl/habrok/additional_information/job_hints

Acknowledgements:
=================

Please see this page for information about acknowledging H치br칩k in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
